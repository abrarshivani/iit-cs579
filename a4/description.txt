In this assignment, I have analyzed the sentiments of the movie from tweets obtained from the Twitter.

collect.py
In 'collect.py', I have collected tweets using streaming api of the Twitter and stored in a file.
While collecting tweets from Twitter, I have simultaneously collected user ids of users who posted these tweets.
I have used 'streaming api' for collecting tweets since it is better in terms of Twitter rate limit. Now, to collect
friends ids simultaneously, I have used producer-consumer model where tweets collection is producer and friends id collecter
is consumer. That is, once tweet is received from Twitter it is enqueued in queue and then it is dequeued by another thread,
which fetches friends ids from Twitter and stored in a file.

cluster.py
User's friends stored in a file by collect.py are read by cluster.py. These data is used in cluster.py to detect communities in the users
who posted these tweets. Graph is created in cluster.py where nodes are user_ids and edges are drawn based on jaccard similarity. Friends of
one user is matched with all other users to calculate jaccard similarity and if one similarity is greater than some threshold then
edge is added. Once the graph is drawn, the communities are detected using girwan_newman algorithm and results are summarized into a file.


classify.py
Tweets stored in a file by collect.py are read by classify.py. These data is used in classify.py to detect sentiments of the tweets.
I have used machine learning approach to detect sentiments. Hence, I have used imdb data to train the classifier. The classifier
I used is svm. I figured out that svm is better than logistic regression in text analysis. I have used multiple settings and detected
setting that has better accuracy. Once, the classifier is trained, I used this to predicte the class of tweets. Now, tweets contain lots
of noise, hence I applied various pre-processing techniques to clean tweets. This improved overall accuracy to 80%. Thereafter, I have stored
summarized result into a file.

summarize.py
summarize.py collect summary written for communities detection and sentiments and store that into summary.txt.


Analysis
In collect.py, I get tweets for multiple movies. These movies are of different genres. Hence, in cluster.py we get
communities of users who like different genres of movie. Similarly, we get sentiments of tweet for different movies.
I observed that we need to implement more context based processing for tweets since we need to know if the tweet is
about movie or some other object i.e we need to differentiate with 'Anconda' as movie or snake or python package.
Also, we need to analyze the sentiment properly for sarcasm.
